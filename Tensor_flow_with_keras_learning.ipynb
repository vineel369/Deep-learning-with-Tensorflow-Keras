{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf # Imports the tensor flow library\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = tf.constant('Welcome to the exciting world of Deep Neural Networks!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the message we want to print is a constant string, we use tf.constant:\n",
    "\n",
    "To execute the graph element, we need to define the **Session** using **with** and **run** the session using run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the exciting world of Deep Neural Networks!\n",
      "b'Welcome to the exciting world of Deep Neural Networks!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     print(sess.run(message).decode()) # with decode\n",
    "\n",
    "session = tf.Session()\n",
    "print(session.run(message))# with out decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist # 28 x 28 images of handwritten digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train),(X_test,y_test) = mnist.load_data() # loading the mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xefb7128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel data is varying from 0 to 255 and it is better to normalize the pixel data using tf normalize option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf331390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building using keras sequential type of model and there are three types of models in keras API\n",
    "\n",
    "**The Sequential Model**\n",
    "    - Dead simple\n",
    "    - Only for single-input, single-output, sequential layer stacks\n",
    "    - Good for 70+% of use cases\n",
    "**The functional API**\n",
    "    - Like playing with Lego bricks\n",
    "    - Multi-input, multi-output, arbitrary static graph topologies\n",
    "    - Good for 95% of use cases\n",
    "**Model subclassing**\n",
    "    - Maximum flexibility\n",
    "    - Larger potential error surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST images are like 28 X 28 multi dimensional array. But, we want them to be a flatten (single column),which can be achieved either by using numpy,reshape or we can use one of the layers that's built into keras which is flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten()) # Input layer\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # Hidden layer 1\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # Hidden layer 2\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))*\n",
    "- It defines a hidden layer with 128 neurons/units, connected to the input layer or previous hidden layer that use relu activation function.\n",
    "\n",
    "*model.add(Dense(128, input_dim=8, init='uniform', activation='relu'))*\n",
    "- It defines the input layer as having 8 units\n",
    "- It defines a hidden layer with 128 neurons/units, connected to the input layer that use relu activation function.\n",
    "- It initializes all weights using a sample of unfirom random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is defined, we can compile it.\n",
    "\n",
    "When compiling, we must specify some additional properties required when training the network. \n",
    "\n",
    "- Must specify the loss function to evaluate the weights\n",
    "- Must specify the optimizer, which will do search through different weights for the network\n",
    "- Optional metrics, would like to collect & report during training\n",
    "\n",
    "*Remember training a network means finding the best set of weights to make predictions for this problem.*\n",
    "\n",
    "In this case, we will use logarithmic loss, which for a Multi classification problem. For this example, we are considering “sparse_categorical_crossentropy“ as loss parameter. We will also use the efficient gradient descent algorithm “adam” for no other reason that it is an efficient default. Learn more about the Adam optimization algorithm in the paper [“Adam: A Method for Stochastic Optimization“.](http://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined our model and compiled it ready for computation. Now it is time to fit the model on mnist data\n",
    "\n",
    "- We can train or fit our model on our loaded data by calling the **fit()** function on the model.\n",
    "\n",
    "The training process will run for a fixed number of iterations through the dataset called **epochs**, that we must specify using the **nepochs** argument. We can also set the number of instances that are evaluated before a weight update in the network is performed, called the **batch size** and set using the **batch_size** argument.\n",
    "\n",
    "- Epoch is just a \"full pass\" through your entire training dataset. 3 epochs means it passed over your data set 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.2176 - acc: 0.9348\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0969 - acc: 0.9694\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0685 - acc: 0.9783\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0521 - acc: 0.9833\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0407 - acc: 0.9865\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0330 - acc: 0.98900s - loss: 0.0329 - acc\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0272 - acc: 0.9911\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0236 - acc: 0.9919\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0199 - acc: 0.9932\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0190 - acc: 0.9937\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0164 - acc: 0.9943\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0177 - acc: 0.9945\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0134 - acc: 0.9959\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0132 - acc: 0.9962\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0134 - acc: 0.9959\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0110 - acc: 0.9969\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0126 - acc: 0.9966\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0099 - acc: 0.9972\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0110 - acc: 0.9973\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0102 - acc: 0.9971\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0100 - acc: 0.9975\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0090 - acc: 0.9975\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0088 - acc: 0.9981\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0090 - acc: 0.9980\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0103 - acc: 0.9977\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0096 - acc: 0.9978\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0077 - acc: 0.9980\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0094 - acc: 0.9981\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0096 - acc: 0.9981\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0069 - acc: 0.9986\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0086 - acc: 0.9981\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0071 - acc: 0.9986\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0093 - acc: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xf381400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 50, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained our neural network on the train dataset and we can evaluate the performance of the network on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "0.2571990268678714 0.9755\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 4.7248140e-33]\n",
      " [0.0000000e+00 1.0149464e-29 1.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.2066167e-33 ... 4.9846245e-29\n",
      "  3.1889327e-24 3.8095756e-28]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  2.0714089e-31 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Save the current model and load the model \n",
    "\n",
    "# model.save('number_reader_model')\n",
    "# new_model = tf.keras.models.load_model('number_reader_model')\n",
    "predictions = model.predict([X_test])   #predict always takes a list\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADXdJREFUeJzt3W+IVfedx/HPx4l/gkpQnKjYyU5TxGwIrF0mspCwuJY0cWlifKDog2JC6fRBA1vogw0+aZ4shGXbbh4sJXYjGmjTlrRZJchugwRccQm5CdKk626U4NaJgzPGxFqCkYnffTDHMjVzz73ef+fOfN8vkHvv+Z5zzzcnfjz33t+59+eIEIB8FlTdAIBqEH4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0nd1sudrVq1KoaHh3u5SyCVs2fP6uLFi25m3bbCb/sRSc9JGpD0rxHxbNn6w8PDqtVq7ewSQImRkZGm1235Zb/tAUn/ImmrpHsl7bZ9b6vPB6C32nnPv0nSmYh4PyKuSfqZpG2daQtAt7UT/nWSzs14PFYs+xO2R23XbNcmJyfb2B2ATmon/LN9qPC57wdHxL6IGImIkcHBwTZ2B6CT2gn/mKShGY+/IOl8e+0A6JV2wv+mpPW2v2h7kaRdkg53pi0A3dbyUF9ETNl+StJ/aHqob39E/LZjnQHoqrbG+SPiiKQjHeoFQA9xeS+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJtTVLr+2zkq5I+kzSVESMdKIpAN3XVvgLfxMRFzvwPAB6iJf9QFLthj8k/dr2W7ZHO9EQgN5o92X/AxFx3vadkl6z/T8RcWzmCsU/CqOSdNddd7W5OwCd0taZPyLOF7cTkl6RtGmWdfZFxEhEjAwODrazOwAd1HL4bS+1vfzGfUlflfRupxoD0F3tvOxfLekV2zee56cR8e8d6QpA17Uc/oh4X9JfdLAXAD3EUB+QFOEHkiL8QFKEH0iK8ANJEX4gqU58qy+FAwcO1K0dO3asbk2Sli1bVlpfunRpaX3Xrl2l9aGhobq1lStXlm6LvDjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjPM36cknn6xb27BhQ+m2ly5dKq0vWrSotH706NHS+vbt2+vWhoeHS7e97bbyvwKXL18urUdEaX3Bgvrnl0b7npqaKq032v6TTz6pW1u7dm3pto8//nhpfT7gzA8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHO36TDhw/XrX344Yel2zaapuzMmTOl9Q8++KC0vnjx4rq18fHx0m0bfd//3LlzpfVG4/wDAwN1a2V9S9LChQtL659++mlpvey4njhxonRbxvkBzFuEH0iK8ANJEX4gKcIPJEX4gaQIP5BUw3F+2/slfU3SRETcVyxbKennkoYlnZW0MyI+6l6b1Xv00Ue79txbtmxpa/urV6/WrU1OTpZuu3r16tL62NhYSz3dYLturdE4fqNrEJ5//vmWepKk+++/v+Vt54tmzvwHJD1y07KnJR2NiPWSjhaPAcwhDcMfEcck3fxTNNskHSzuH5Q0/y+HAuaZVt/zr46IcUkqbu/sXEsAeqHrH/jZHrVds11r9P4TQO+0Gv4LttdKUnE7UW/FiNgXESMRMTI4ONji7gB0WqvhPyxpT3F/j6RDnWkHQK80DL/tlyT9l6QNtsdsf0PSs5Iesn1a0kPFYwBzSMNx/ojYXaf0lQ73ghYtWbKkbm1oaKit57777rvb2r4dp06dKq2XXd8glf+3j46OttTTfMIVfkBShB9IivADSRF+ICnCDyRF+IGk+OluVKZsCm1JevXVV0vrjX42/LHHHqtbW7duXem2GXDmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkGOdHZWq1Wmm90XUAy5cvL62vWbPmlnvKhDM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOD+66ty5c3VrJ06caOu5d+zYUVrnO/vlOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFINx/lt75f0NUkTEXFfsewZSd+UNFmstjcijnSrScxdp0+frlu7fv166baNpgdnHL89zZz5D0h6ZJblP4yIjcUfgg/MMQ3DHxHHJF3qQS8Aeqid9/xP2f6N7f22V3SsIwA90Wr4fyTpS5I2ShqX9P16K9oetV2zXZucnKy3GoAeayn8EXEhIj6LiOuSfixpU8m6+yJiJCJGBgcHW+0TQIe1FH7ba2c83C7p3c60A6BXmhnqe0nSZkmrbI9J+p6kzbY3SgpJZyV9q4s9AuiChuGPiN2zLH6hC71gDpqamiqtnzlzpm5tYGCgdNvNmzeX1hcs4Bq1dnD0gKQIP5AU4QeSIvxAUoQfSIrwA0nx091oy/Hjx0vr4+PjdWv33HNP6bZDQ0Mt9YTmcOYHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY50ep9957r7T++uuvl9Zvv/32urUHH3ywpZ7QGZz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvmTu3r1amn9yJHyCZgjorS+fv36ujWm2K4WZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrhOL/tIUkvSloj6bqkfRHxnO2Vkn4uaVjSWUk7I+Kj7rWKVjQahz906FBp/aOPyv+Xrly5srS+ZcuW0jqq08yZf0rSdyPizyX9laRv275X0tOSjkbEeklHi8cA5oiG4Y+I8Yh4u7h/RdIpSeskbZN0sFjtoKTHu9UkgM67pff8toclfVnSG5JWR8S4NP0PhKQ7O90cgO5pOvy2l0n6paTvRMTvb2G7Uds127XJyclWegTQBU2F3/ZCTQf/JxHxq2LxBdtri/paSROzbRsR+yJiJCJGBgcHO9EzgA5oGH7blvSCpFMR8YMZpcOS9hT390gq/9gYQF9p5iu9D0j6uqR3bJ8slu2V9KykX9j+hqTfSdrRnRbRjo8//ri0PjEx6wu2pm3durW0vmLFiraeH93TMPwRcVyS65S/0tl2APQKV/gBSRF+ICnCDyRF+IGkCD+QFOEHkuKnu+eBy5cv1629/PLLbT33ww8/XFrfsGFDW8+P6nDmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkGOefB2q1Wt3alStXSrdduHBhaX14eLiVljAHcOYHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY558DTp48WVp/44036taWLFnS6XYwT3DmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkGo7z2x6S9KKkNZKuS9oXEc/ZfkbSNyVNFqvujYgj3Wo0s0bj/NeuXatbazTOf8cdd5TWFy1aVFrH3NXMRT5Tkr4bEW/bXi7pLduvFbUfRsQ/da89AN3SMPwRMS5pvLh/xfYpSeu63RiA7rql9/y2hyV9WdKN60mfsv0b2/ttr6izzajtmu3a5OTkbKsAqEDT4be9TNIvJX0nIn4v6UeSviRpo6ZfGXx/tu0iYl9EjETEyODgYAdaBtAJTYXf9kJNB/8nEfErSYqICxHxWURcl/RjSZu61yaATmsYftuW9IKkUxHxgxnL185YbbukdzvfHoBuaebT/gckfV3SO7ZvjDntlbTb9kZJIemspG91pUO0pdFbrZ07d5bWFy9e3Ml20Eea+bT/uCTPUmJMH5jDuMIPSIrwA0kRfiApwg8kRfiBpAg/kBQ/3T0HPPHEE1W3gHmIMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJOWI6N3O7ElJ/zdj0SpJF3vWwK3p1976tS+J3lrVyd7+LCKa+r28nob/czu3axExUlkDJfq1t37tS6K3VlXVGy/7gaQIP5BU1eHfV/H+y/Rrb/3al0Rvraqkt0rf8wOoTtVnfgAVqST8th+x/b+2z9h+uooe6rF91vY7tk/arlXcy37bE7bfnbFspe3XbJ8ubmedJq2i3p6x/UFx7E7a/tuKehuy/brtU7Z/a/vviuWVHruSvio5bj1/2W97QNJ7kh6SNCbpTUm7I+K/e9pIHbbPShqJiMrHhG3/taQ/SHoxIu4rlv2jpEsR8WzxD+eKiPj7PuntGUl/qHrm5mJCmbUzZ5aW9LikJ1ThsSvpa6cqOG5VnPk3SToTEe9HxDVJP5O0rYI++l5EHJN06abF2yQdLO4f1PRfnp6r01tfiIjxiHi7uH9F0o2ZpSs9diV9VaKK8K+TdG7G4zH115TfIenXtt+yPVp1M7NYXUybfmP69Dsr7udmDWdu7qWbZpbum2PXyozXnVZF+Geb/aefhhweiIi/lLRV0reLl7doTlMzN/fKLDNL94VWZ7zutCrCPyZpaMbjL0g6X0Efs4qI88XthKRX1H+zD1+4MUlqcTtRcT9/1E8zN882s7T64Nj104zXVYT/TUnrbX/R9iJJuyQdrqCPz7G9tPggRraXSvqq+m/24cOS9hT390g6VGEvf6JfZm6uN7O0Kj52/TbjdSUX+RRDGf8saUDS/oj4h543MQvbd2v6bC9N/7LxT6vszfZLkjZr+ltfFyR9T9K/SfqFpLsk/U7Sjojo+QdvdXrbrOmXrn+cufnGe+we9/agpP+U9I6k68XivZp+f13ZsSvpa7cqOG5c4QckxRV+QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS+n+17MODM/tzuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5b99908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
